{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b282856",
   "metadata": {},
   "source": [
    "Refer: E:\\ANG\\Gradio\\Building Generative AI Applications with Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88535ead",
   "metadata": {},
   "source": [
    "# L1: NLP tasks with a simple interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a99c3",
   "metadata": {},
   "source": [
    "## Building a text summarization app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa43ba",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4794502",
   "metadata": {},
   "source": [
    "Here we are using an [Inference Endpoint](https://huggingface.co/inference-endpoints) for the `shleifer/distilbart-cnn-12-6`, a 306M parameter distilled model from `facebook/bart-large-cnn`. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c69264f",
   "metadata": {},
   "source": [
    "HF_API_SUMMARY_BASE=\"https://api-inference.huggingface.co/models/sshleifer/distilbart-cnn-12-6\"\n",
    "HF_API_NER_BASE=\"https://api-inference.huggingface.co/models/dslim/bert-base-NER\"\n",
    "HF_API_ITT_BASE=\"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base\"\n",
    "HF_API_TTI_BASE=\"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5\"\n",
    "HF_API_MIXTRAL_BASE=\"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a",
   "metadata": {
    "height": 166,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106ab02-f248-4c03-9dd8-b1991db7f778",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "API_URL = os.environ['HF_API_SUMMARY_BASE']\n",
    "\n",
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=API_URL): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb11460",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "    \n",
    "gr.close_all()  # demo.close()\n",
    "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()  # demo.close()\n",
    "demo = gr.Interface(fn=summarize, \n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "                    title=\"Text summarization with distilbart-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
    "                   )\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b300d17",
   "metadata": {},
   "source": [
    "## Building a Named Entity Recognition app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1043f",
   "metadata": {},
   "source": [
    "We are using this [Inference Endpoint](https://huggingface.co/inference-endpoints) for `dslim/bert-base-NER`, a 108M parameter fine-tuned BART model on the NER task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5471ef2",
   "metadata": {
    "height": 166,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f9da4",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
    "\n",
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=API_URL): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4a922-b300-4dbc-8768-955b6a18dce4",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "get_completion(text, parameters=None, ENDPOINT_URL= API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c21254-128d-446c-b6dd-e30af26d436d",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
    "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16ad4",
   "metadata": {},
   "source": [
    "### Adding a helper function to merge tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91141b6",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if merged_tokens and token['entity_group'].startswith('I-') and merged_tokens[-1]['entity_group'].endswith(token['entity_group'][2:]):\n",
    "            # If current token continues the entity of the last one, merge them\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            # Otherwise, add the token to the list\n",
    "            merged_tokens.append(token)\n",
    "\n",
    "    return merged_tokens\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()  # demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf933f7",
   "metadata": {},
   "source": [
    "# L2: Image captioning app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8996b4",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3471d1ed-41a0-473c-b3c7-99a9e14dffaf",
   "metadata": {
    "height": 149,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05896028-3b43-408e-a899-109bde9625e5",
   "metadata": {
    "height": 302,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import requests, json\n",
    "\n",
    "#Image-to-text endpoint\n",
    "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7154b9-fa1c-416e-8ee2-635c27720539",
   "metadata": {
    "height": 64,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n",
    "display(IPython.display.Image(url=image_url))\n",
    "get_completion(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da616d",
   "metadata": {},
   "source": [
    "## Captioning with `gr.Interface()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8021fac0-9300-44d5-adb1-6ac7111f38f6",
   "metadata": {
    "height": 404,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr \n",
    "\n",
    "def image_to_base64_str(pil_image):\n",
    "    byte_arr = io.BytesIO()\n",
    "    pil_image.save(byte_arr, format='PNG')\n",
    "    byte_arr = byte_arr.getvalue()\n",
    "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
    "\n",
    "def captioner(image):\n",
    "    base64_image = image_to_base64_str(image)\n",
    "    result = get_completion(base64_image)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=captioner,\n",
    "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
    "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
    "                    title=\"Image Captioning with BLIP\",\n",
    "                    description=\"Caption any image using the BLIP model\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    # examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"]\n",
    "                    examples=[\"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\", \"https://free-images.com/md/850e/cow_beef_alm_cows.jpg\", \"https://free-images.com/md/2b9d/bird_wildlife_sky_clouds.jpg\"])\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56748b3",
   "metadata": {
    "height": 30,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c635960",
   "metadata": {},
   "source": [
    "# L3: Image generation app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c186d0",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0447fb8-b684-4835-9a31-1d0a824d2607",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr \n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b5677-271a-46ac-a02e-656f2e315e15",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "#Text-to-image endpoint\n",
    "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }   \n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a85ed",
   "metadata": {},
   "source": [
    "## Building an image generation app "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fab52",
   "metadata": {},
   "source": [
    "Here we are going to run `runwayml/stable-diffusion-v1-5` using the `diffusers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28748bf-2618-4b8c-aa6f-7aad9c573af8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"a dog in a park\"\n",
    "\n",
    "result = get_completion(prompt)\n",
    "display(HTML(f'<img src=\"data:image/png;base64,{base64.b64encode(result).decode()}\" />'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee90440",
   "metadata": {},
   "source": [
    "## Generating with `gr.Interface()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024026ce-7832-4749-8992-50d31d61fcda",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#A helper function to convert the PIL image to base64 so you can send it to the API\n",
    "def base64_to_pil(img_base64):\n",
    "    pil_image = Image.open(io.BytesIO(img_base64))\n",
    "    return pil_image\n",
    "\n",
    "def generate(prompt):\n",
    "    output = get_completion(prompt)\n",
    "    result_image = base64_to_pil(output)\n",
    "    return result_image\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=generate,\n",
    "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a7330",
   "metadata": {},
   "source": [
    "## Building a more advanced interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c844370-4c46-4115-858e-f5cd5fe337ab",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#A helper function to convert the PIL image to base64 so you can send it to the API\n",
    "def base64_to_pil(img_base64):\n",
    "    pil_image = Image.open(io.BytesIO(img_base64))\n",
    "    return pil_image\n",
    "\n",
    "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
    "    params = {\n",
    "        \"negative_prompt\": negative_prompt,\n",
    "        \"num_inference_steps\": steps,\n",
    "        \"guidance_scale\": guidance,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    }\n",
    "    \n",
    "    output = get_completion(prompt, params)\n",
    "    pil_image = base64_to_pil(output)\n",
    "    return pil_image\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=generate,\n",
    "                    inputs=[\n",
    "                        gr.Textbox(label=\"Your prompt\"),\n",
    "                        gr.Textbox(label=\"Negative prompt\"),\n",
    "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "                                  info=\"Controls how much the text prompt influences the result\"),\n",
    "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "                    ],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\"\n",
    "                    )\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71999364",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95b525",
   "metadata": {},
   "source": [
    "## `gr.Blocks()` to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6818b5e-1342-439b-b129-a8904719d09c",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    prompt = gr.Textbox(label=\"Your prompt\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "            btn = gr.Button(\"Submit\")\n",
    "        with gr.Column():\n",
    "            output = gr.Image(label=\"Result\")\n",
    "\n",
    "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655908ab-fa08-4b86-b218-f685f62d3638",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
    "        with gr.Column(scale=1, min_width=50):\n",
    "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
    "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "                with gr.Column():\n",
    "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "    output = gr.Image(label=\"Result\") #Move the output up too\n",
    "            \n",
    "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e8671",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()  # demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652a472",
   "metadata": {},
   "source": [
    "# L4: Describe-and-Generate game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21aa74",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92f16527-fcab-41e0-bce8-634fae58b1b8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr \n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac9eab7f-4013-42ec-b34e-b413b0f8adb6",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "#Here we are going to call multiple endpoints!\n",
    "def get_completion(inputs, parameters=None, ENDPOINT_URL=\"\"):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }   \n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "#Above helper function return is not working for Text to Image Endpoints. There is some conversion issue with 'utf-8' in windows\n",
    "def get_completion_TTI(inputs, parameters=None, ENDPOINT_URL=\"\"):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }   \n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52cb1837",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#text-to-image\n",
    "TTI_ENDPOINT = os.environ['HF_API_TTI_BASE']\n",
    "#image-to-text\n",
    "ITT_ENDPOINT = os.environ['HF_API_ITT_BASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9c4d4",
   "metadata": {},
   "source": [
    "## Building your game with `gr.Blocks()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76170d93-0de0-4359-8f13-3d1bcc41f86a",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#Bringing the functions from lessons 3 and 4!\n",
    "def image_to_base64_str(pil_image):\n",
    "    byte_arr = io.BytesIO()\n",
    "    pil_image.save(byte_arr, format='PNG')\n",
    "    byte_arr = byte_arr.getvalue()\n",
    "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
    "\n",
    "def base64_to_pil(img_base64):\n",
    "    pil_image = Image.open(io.BytesIO(img_base64))\n",
    "    return pil_image\n",
    "\n",
    "def captioner(image):\n",
    "    base64_image = image_to_base64_str(image)\n",
    "    result = get_completion(base64_image, None, ITT_ENDPOINT)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "def generate(prompt):\n",
    "    output = get_completion_TTI(prompt, None, TTI_ENDPOINT)\n",
    "    result_image = base64_to_pil(output)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f3485",
   "metadata": {},
   "source": [
    "### First attempt, just captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64e403a9-bfcb-47e8-b741-743d5f4980fd",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Describe-and-Generate game\")\n",
    "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "    btn_caption = gr.Button(\"Generate caption\")\n",
    "    caption = gr.Textbox(label=\"Generated caption\")\n",
    "    \n",
    "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cd4e8",
   "metadata": {},
   "source": [
    "### Let's add generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5ea9a93-9f97-43f8-86ca-2e8e4ea9dda8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Describe-and-Generate game\")\n",
    "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "    btn_caption = gr.Button(\"Generate caption\")\n",
    "    caption = gr.Textbox(label=\"Generated caption\")\n",
    "    btn_image = gr.Button(\"Generate image\")\n",
    "    image_output = gr.Image(label=\"Generated Image\")\n",
    "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
    "    btn_image.click(fn=generate, inputs=[caption], outputs=[image_output])\n",
    "\n",
    "gr.close_all() # demo.close()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da53d1",
   "metadata": {},
   "source": [
    "### Doing it all at once! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "024a4529-7f38-41fb-aab3-c38525b61abe",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def caption_and_generate(image):\n",
    "    caption = captioner(image)\n",
    "    image = generate(caption)\n",
    "    return [caption, image]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Describe-and-Generate game\")\n",
    "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "    btn_all = gr.Button(\"Caption and generate\")\n",
    "    caption = gr.Textbox(label=\"Generated caption\")\n",
    "    image_output = gr.Image(label=\"Generated Image\")\n",
    "\n",
    "    btn_all.click(fn=caption_and_generate, inputs=[image_upload], outputs=[caption, image_output])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f1e16e3d",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5753a0c",
   "metadata": {},
   "source": [
    "# L5: Chat with any LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a3724",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6fa00-6bd1-4839-bcaf-8bae9267ee79",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095da8fe-24aa-4dc7-8e08-aa2f949ae21f",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "from text_generation import Client\n",
    "\n",
    "#FalcomLM-instruct endpoint on the text_generation library\n",
    "# client = Client(os.environ['HF_API_FALCOM_BASE'], headers={\"Authorization\": f\"Basic {hf_api_key}\"}, timeout=120)\n",
    "#MixTral endpoint on the text_generation library\n",
    "client = Client(os.environ['HF_API_MIXTRAL_BASE'], headers={\"Authorization\": f\"Bearer {hf_api_key}\"}, timeout=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6fc97",
   "metadata": {},
   "source": [
    "## Building an app to chat with any LLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a3c9b",
   "metadata": {},
   "source": [
    "Here we'll be using an [Inference Endpoint](https://huggingface.co/inference-endpoints) for `falcon-40b-instruct` , one of best ranking open source LLM on the [ðŸ¤— Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard). \n",
    "\n",
    "To run it locally, one can use the [Transformers library](https://huggingface.co/docs/transformers/index) or the [text-generation-inference](https://github.com/huggingface/text-generation-inference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7065860-3c0b-490d-9e7c-22e5b79fc004",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Has math been invented or discovered?\"\n",
    "client.generate(prompt, max_new_tokens=256).generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb659e-b71b-46da-b9d2-6ee62498995f",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#Back to Lesson 2, time flies!\n",
    "import gradio as gr\n",
    "def generate(input, slider):\n",
    "    output = client.generate(input, max_new_tokens=slider).generated_text\n",
    "    return output\n",
    "\n",
    "demo = gr.Interface(fn=generate, inputs=[gr.Textbox(label=\"Prompt\"), gr.Slider(label=\"Max new tokens\", value=20,  maximum=1024, minimum=1)], outputs=[gr.Textbox(label=\"Completion\")])\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a123619",
   "metadata": {},
   "source": [
    "#### Implementation using ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f81207a",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client = OpenAI(api_key=os.environ['OPAI_API_KEY'])\n",
    "\n",
    "def chatopenaigenerate(prompt,max_new_tokens):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_new_tokens\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "#Back to Lesson 2, time flies!\n",
    "def generate(input, slider):\n",
    "    output = chatopenaigenerate(input, max_new_tokens=slider)\n",
    "    return output\n",
    "\n",
    "demo = gr.Interface(fn=generate, inputs=[gr.Textbox(label=\"Prompt\"), gr.Slider(label=\"Max new tokens\", value=20,  maximum=1024, minimum=1)], outputs=[gr.Textbox(label=\"Completion\")])\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f55e2",
   "metadata": {},
   "source": [
    "## `gr.Chatbot()` to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43beebb7-40a6-4af5-a701-882821b6ed36",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# With Dummy Response\n",
    "import random\n",
    "\n",
    "def respond(message, chat_history):\n",
    "        #No LLM here, just respond with a random pre-made message\n",
    "        bot_message = random.choice([\"Tell me more about it\", \n",
    "                                     \"Cool, but I'm not interested\", \n",
    "                                     \"Hmmmm, ok then\"]) \n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bae99d-7a63-4a40-bab7-de7d10b8ab1b",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(message, chat_history):\n",
    "        formatted_prompt = format_chat_prompt(message, chat_history)\n",
    "        bot_message = client.generate(formatted_prompt,\n",
    "                                     max_new_tokens=1024,\n",
    "                                     stop_sequences=[\"\\nUser:\", \"<|endoftext|>\"]).generated_text\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79d107f3",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3214f5",
   "metadata": {},
   "source": [
    "#### Implementation using ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6218a973",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client = OpenAI(api_key=os.environ['OPAI_API_KEY'])\n",
    "\n",
    "def chatopenaigenerate(prompt,max_new_tokens):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_new_tokens\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(message, chat_history):\n",
    "        formatted_prompt = format_chat_prompt(message, chat_history)\n",
    "        bot_message = chatopenaigenerate(formatted_prompt,\n",
    "                                     max_new_tokens=100)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "\n",
    "gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b8de8",
   "metadata": {},
   "source": [
    "### Adding other advanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09873dfd-5b6c-41d6-9479-12e8c8894295",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def format_chat_prompt(message, chat_history, instruction):\n",
    "    prompt = f\"System:{instruction}\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(message, chat_history, instruction, temperature=0.7):\n",
    "    prompt = format_chat_prompt(message, chat_history, instruction)\n",
    "    chat_history = chat_history + [[message, \"\"]]\n",
    "    stream = client.generate_stream(prompt,\n",
    "                                      max_new_tokens=1024,\n",
    "                                      stop_sequences=[\"\\nUser:\", \"<|endoftext|>\"],\n",
    "                                      temperature=temperature)\n",
    "                                      #stop_sequences to not generate the user answer\n",
    "    acc_text = \"\"\n",
    "    #Streaming the tokens\n",
    "    for idx, response in enumerate(stream):\n",
    "            text_token = response.token.text\n",
    "\n",
    "            if response.details:\n",
    "                return\n",
    "\n",
    "            if idx == 0 and text_token.startswith(\" \"):\n",
    "                text_token = text_token[1:]\n",
    "\n",
    "            acc_text += text_token\n",
    "            last_turn = list(chat_history.pop(-1))\n",
    "            last_turn[-1] += acc_text\n",
    "            chat_history = chat_history + [last_turn]\n",
    "            yield \"\", chat_history\n",
    "            acc_text = \"\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "        system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "        temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "\n",
    "# In Gradio, both demo.queue().launch() and demo.launch() are used to launch a Gradio interface, but they serve different purposes:\n",
    "\n",
    "# demo.launch(): This is the standard way to launch a Gradio interface. It starts a simple web server that serves the demo.\n",
    "# demo.queue().launch(): This is used when you want to set up a queue for your Gradio interface. The queue helps manage multiple incoming requests, ensuring that they are processed in the order they were received. This can be particularly useful when youâ€™re expecting high traffic or when the function associated with your interface takes a significant amount of time to process.\n",
    "# demo.queue().launch(share=True, server_port=int(os.environ['PORT4']))\n",
    "demo.queue().launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT4']))  # demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b0220",
   "metadata": {},
   "source": [
    "#### Implementation using ChatOpenAI (Steaming and Stop Sequence is not implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "711c34e0",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client = OpenAI(api_key=os.environ['OPAI_API_KEY'])\n",
    "\n",
    "def chatopenaigenerate(prompt,instruction,temperature,max_new_tokens=1000):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": instruction\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "#         stream=True\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "    \n",
    "def respond(message, chat_history, instruction, temperature=0.7):\n",
    "    prompt = format_chat_prompt(message, chat_history)\n",
    "    bot_message = chatopenaigenerate(prompt,\n",
    "                                      instruction,\n",
    "                                      temperature=temperature,\n",
    "                                      max_new_tokens=1000)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "        system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "        temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "\n",
    "demo.queue().launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT5']))  # demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d9ec80a-39ad-4f58-b79e-4f413c5074c0",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7864\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "465.475px",
    "left": "10px",
    "top": "150px",
    "width": "158.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
