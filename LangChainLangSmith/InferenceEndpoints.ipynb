{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b282856",
   "metadata": {},
   "source": [
    "Refer: E:\\ANG\\Gradio\\Building Generative AI Applications with Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88535ead",
   "metadata": {},
   "source": [
    "# L1: NLP tasks with a simple interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a99c3",
   "metadata": {},
   "source": [
    "## Building a text summarization app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa43ba",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4794502",
   "metadata": {},
   "source": [
    "Here we are using an [Inference Endpoint](https://huggingface.co/inference-endpoints) for the `shleifer/distilbart-cnn-12-6`, a 306M parameter distilled model from `facebook/bart-large-cnn`. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c69264f",
   "metadata": {},
   "source": [
    "HF_API_SUMMARY_BASE=\"https://api-inference.huggingface.co/models/sshleifer/distilbart-cnn-12-6\"\n",
    "HF_API_NER_BASE=\"https://api-inference.huggingface.co/models/dslim/bert-base-NER\"\n",
    "HF_API_ITT_BASE=\"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base\"\n",
    "HF_API_TTI_BASE=\"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5\"\n",
    "HF_API_MIXTRAL_BASE=\"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a",
   "metadata": {
    "height": 166,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106ab02-f248-4c03-9dd8-b1991db7f778",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "API_URL = os.environ['HF_API_SUMMARY_BASE']\n",
    "\n",
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=API_URL): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb11460",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "    \n",
    "gr.close_all()  # demo.close()\n",
    "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()  # demo.close()\n",
    "demo = gr.Interface(fn=summarize, \n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "                    title=\"Text summarization with distilbart-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
    "                   )\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b300d17",
   "metadata": {},
   "source": [
    "## Building a Named Entity Recognition app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1043f",
   "metadata": {},
   "source": [
    "We are using this [Inference Endpoint](https://huggingface.co/inference-endpoints) for `dslim/bert-base-NER`, a 108M parameter fine-tuned BART model on the NER task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5471ef2",
   "metadata": {
    "height": 166,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f9da4",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
    "\n",
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=API_URL): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4a922-b300-4dbc-8768-955b6a18dce4",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "get_completion(text, parameters=None, ENDPOINT_URL= API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c21254-128d-446c-b6dd-e30af26d436d",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
    "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16ad4",
   "metadata": {},
   "source": [
    "### Adding a helper function to merge tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91141b6",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if merged_tokens and token['entity_group'].startswith('I-') and merged_tokens[-1]['entity_group'].endswith(token['entity_group'][2:]):\n",
    "            # If current token continues the entity of the last one, merge them\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            # Otherwise, add the token to the list\n",
    "            merged_tokens.append(token)\n",
    "\n",
    "    return merged_tokens\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()  # demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf933f7",
   "metadata": {},
   "source": [
    "# L2: Image captioning app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8996b4",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3471d1ed-41a0-473c-b3c7-99a9e14dffaf",
   "metadata": {
    "height": 149,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05896028-3b43-408e-a899-109bde9625e5",
   "metadata": {
    "height": 302,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import requests, json\n",
    "\n",
    "#Image-to-text endpoint\n",
    "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7154b9-fa1c-416e-8ee2-635c27720539",
   "metadata": {
    "height": 64,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n",
    "display(IPython.display.Image(url=image_url))\n",
    "get_completion(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da616d",
   "metadata": {},
   "source": [
    "## Captioning with `gr.Interface()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8021fac0-9300-44d5-adb1-6ac7111f38f6",
   "metadata": {
    "height": 404,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr \n",
    "\n",
    "def image_to_base64_str(pil_image):\n",
    "    byte_arr = io.BytesIO()\n",
    "    pil_image.save(byte_arr, format='PNG')\n",
    "    byte_arr = byte_arr.getvalue()\n",
    "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
    "\n",
    "def captioner(image):\n",
    "    base64_image = image_to_base64_str(image)\n",
    "    result = get_completion(base64_image)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=captioner,\n",
    "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
    "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
    "                    title=\"Image Captioning with BLIP\",\n",
    "                    description=\"Caption any image using the BLIP model\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    # examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"]\n",
    "                    examples=[\"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\", \"https://free-images.com/md/850e/cow_beef_alm_cows.jpg\", \"https://free-images.com/md/2b9d/bird_wildlife_sky_clouds.jpg\"])\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56748b3",
   "metadata": {
    "height": 30,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c635960",
   "metadata": {},
   "source": [
    "# L3: Image generation app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c186d0",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0447fb8-b684-4835-9a31-1d0a824d2607",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr \n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b5677-271a-46ac-a02e-656f2e315e15",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "#Text-to-image endpoint\n",
    "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }   \n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a85ed",
   "metadata": {},
   "source": [
    "## Building an image generation app "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fab52",
   "metadata": {},
   "source": [
    "Here we are going to run `runwayml/stable-diffusion-v1-5` using the `diffusers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28748bf-2618-4b8c-aa6f-7aad9c573af8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"a dog in a park\"\n",
    "\n",
    "result = get_completion(prompt)\n",
    "display(HTML(f'<img src=\"data:image/png;base64,{base64.b64encode(result).decode()}\" />'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee90440",
   "metadata": {},
   "source": [
    "## Generating with `gr.Interface()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024026ce-7832-4749-8992-50d31d61fcda",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#A helper function to convert the PIL image to base64 so you can send it to the API\n",
    "def base64_to_pil(img_base64):\n",
    "    pil_image = Image.open(io.BytesIO(img_base64))\n",
    "    return pil_image\n",
    "\n",
    "def generate(prompt):\n",
    "    output = get_completion(prompt)\n",
    "    result_image = base64_to_pil(output)\n",
    "    return result_image\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=generate,\n",
    "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a7330",
   "metadata": {},
   "source": [
    "## Building a more advanced interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c844370-4c46-4115-858e-f5cd5fe337ab",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#A helper function to convert the PIL image to base64 so you can send it to the API\n",
    "def base64_to_pil(img_base64):\n",
    "    pil_image = Image.open(io.BytesIO(img_base64))\n",
    "    return pil_image\n",
    "\n",
    "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
    "    params = {\n",
    "        \"negative_prompt\": negative_prompt,\n",
    "        \"num_inference_steps\": steps,\n",
    "        \"guidance_scale\": guidance,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    }\n",
    "    \n",
    "    output = get_completion(prompt, params)\n",
    "    pil_image = base64_to_pil(output)\n",
    "    return pil_image\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=generate,\n",
    "                    inputs=[\n",
    "                        gr.Textbox(label=\"Your prompt\"),\n",
    "                        gr.Textbox(label=\"Negative prompt\"),\n",
    "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "                                  info=\"Controls how much the text prompt influences the result\"),\n",
    "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "                    ],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\"\n",
    "                    )\n",
    "\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71999364",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95b525",
   "metadata": {},
   "source": [
    "## `gr.Blocks()` to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6818b5e-1342-439b-b129-a8904719d09c",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    prompt = gr.Textbox(label=\"Your prompt\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "            btn = gr.Button(\"Submit\")\n",
    "        with gr.Column():\n",
    "            output = gr.Image(label=\"Result\")\n",
    "\n",
    "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655908ab-fa08-4b86-b218-f685f62d3638",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
    "        with gr.Column(scale=1, min_width=50):\n",
    "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
    "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "                with gr.Column():\n",
    "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "    output = gr.Image(label=\"Result\") #Move the output up too\n",
    "            \n",
    "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e8671",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gr.close_all()  # demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652a472",
   "metadata": {},
   "source": [
    "# L4: Describe-and-Generate game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21aa74",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92f16527-fcab-41e0-bce8-634fae58b1b8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr \n",
    "from distutils.util import strtobool\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac9eab7f-4013-42ec-b34e-b413b0f8adb6",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "#Here we are going to call multiple endpoints!\n",
    "def get_completion(inputs, parameters=None, ENDPOINT_URL=\"\"):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }   \n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "#Above helper function return is not working for Text to Image Endpoints. There is some conversion issue with 'utf-8' in windows\n",
    "def get_completion_TTI(inputs, parameters=None, ENDPOINT_URL=\"\"):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }   \n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL,\n",
    "                                headers=headers,\n",
    "                                data=json.dumps(data))\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52cb1837",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#text-to-image\n",
    "TTI_ENDPOINT = os.environ['HF_API_TTI_BASE']\n",
    "#image-to-text\n",
    "ITT_ENDPOINT = os.environ['HF_API_ITT_BASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9c4d4",
   "metadata": {},
   "source": [
    "## Building your game with `gr.Blocks()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76170d93-0de0-4359-8f13-3d1bcc41f86a",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#Bringing the functions from lessons 3 and 4!\n",
    "def image_to_base64_str(pil_image):\n",
    "    byte_arr = io.BytesIO()\n",
    "    pil_image.save(byte_arr, format='PNG')\n",
    "    byte_arr = byte_arr.getvalue()\n",
    "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
    "\n",
    "def base64_to_pil(img_base64):\n",
    "    pil_image = Image.open(io.BytesIO(img_base64))\n",
    "    return pil_image\n",
    "\n",
    "def captioner(image):\n",
    "    base64_image = image_to_base64_str(image)\n",
    "    result = get_completion(base64_image, None, ITT_ENDPOINT)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "def generate(prompt):\n",
    "    output = get_completion_TTI(prompt, None, TTI_ENDPOINT)\n",
    "    result_image = base64_to_pil(output)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f3485",
   "metadata": {},
   "source": [
    "### First attempt, just captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64e403a9-bfcb-47e8-b741-743d5f4980fd",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Describe-and-Generate game\")\n",
    "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "    btn_caption = gr.Button(\"Generate caption\")\n",
    "    caption = gr.Textbox(label=\"Generated caption\")\n",
    "    \n",
    "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cd4e8",
   "metadata": {},
   "source": [
    "### Let's add generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5ea9a93-9f97-43f8-86ca-2e8e4ea9dda8",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Describe-and-Generate game\")\n",
    "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "    btn_caption = gr.Button(\"Generate caption\")\n",
    "    caption = gr.Textbox(label=\"Generated caption\")\n",
    "    btn_image = gr.Button(\"Generate image\")\n",
    "    image_output = gr.Image(label=\"Generated Image\")\n",
    "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
    "    btn_image.click(fn=generate, inputs=[caption], outputs=[image_output])\n",
    "\n",
    "gr.close_all() # demo.close()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da53d1",
   "metadata": {},
   "source": [
    "### Doing it all at once! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "024a4529-7f38-41fb-aab3-c38525b61abe",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def caption_and_generate(image):\n",
    "    caption = captioner(image)\n",
    "    image = generate(caption)\n",
    "    return [caption, image]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Describe-and-Generate game\")\n",
    "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "    btn_all = gr.Button(\"Caption and generate\")\n",
    "    caption = gr.Textbox(label=\"Generated caption\")\n",
    "    image_output = gr.Image(label=\"Generated Image\")\n",
    "\n",
    "    btn_all.click(fn=caption_and_generate, inputs=[image_upload], outputs=[caption, image_output])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f1e16e3d",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5753a0c",
   "metadata": {},
   "source": [
    "# L5: Chat with any LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a3724",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6fa00-6bd1-4839-bcaf-8bae9267ee79",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095da8fe-24aa-4dc7-8e08-aa2f949ae21f",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "from text_generation import Client\n",
    "\n",
    "#FalcomLM-instruct endpoint on the text_generation library\n",
    "# client = Client(os.environ['HF_API_FALCOM_BASE'], headers={\"Authorization\": f\"Basic {hf_api_key}\"}, timeout=120)\n",
    "#MixTral endpoint on the text_generation library\n",
    "client = Client(os.environ['HF_API_MIXTRAL_BASE'], headers={\"Authorization\": f\"Bearer {hf_api_key}\"}, timeout=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6fc97",
   "metadata": {},
   "source": [
    "## Building an app to chat with any LLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a3c9b",
   "metadata": {},
   "source": [
    "Here we'll be using an [Inference Endpoint](https://huggingface.co/inference-endpoints) for `falcon-40b-instruct` , one of best ranking open source LLM on the [🤗 Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard). \n",
    "\n",
    "To run it locally, one can use the [Transformers library](https://huggingface.co/docs/transformers/index) or the [text-generation-inference](https://github.com/huggingface/text-generation-inference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7065860-3c0b-490d-9e7c-22e5b79fc004",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Has math been invented or discovered?\"\n",
    "client.generate(prompt, max_new_tokens=256).generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb659e-b71b-46da-b9d2-6ee62498995f",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#Back to Lesson 2, time flies!\n",
    "import gradio as gr\n",
    "def generate(input, slider):\n",
    "    output = client.generate(input, max_new_tokens=slider).generated_text\n",
    "    return output\n",
    "\n",
    "demo = gr.Interface(fn=generate, inputs=[gr.Textbox(label=\"Prompt\"), gr.Slider(label=\"Max new tokens\", value=20,  maximum=1024, minimum=1)], outputs=[gr.Textbox(label=\"Completion\")])\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a123619",
   "metadata": {},
   "source": [
    "#### Implementation using ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f81207a",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client = OpenAI(api_key=os.environ['OPAI_API_KEY'])\n",
    "\n",
    "def chatopenaigenerate(prompt,max_new_tokens):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_new_tokens\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "#Back to Lesson 2, time flies!\n",
    "def generate(input, slider):\n",
    "    output = chatopenaigenerate(input, max_new_tokens=slider)\n",
    "    return output\n",
    "\n",
    "demo = gr.Interface(fn=generate, inputs=[gr.Textbox(label=\"Prompt\"), gr.Slider(label=\"Max new tokens\", value=20,  maximum=1024, minimum=1)], outputs=[gr.Textbox(label=\"Completion\")])\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f55e2",
   "metadata": {},
   "source": [
    "## `gr.Chatbot()` to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43beebb7-40a6-4af5-a701-882821b6ed36",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# With Dummy Response\n",
    "import random\n",
    "\n",
    "def respond(message, chat_history):\n",
    "        #No LLM here, just respond with a random pre-made message\n",
    "        bot_message = random.choice([\"Tell me more about it\", \n",
    "                                     \"Cool, but I'm not interested\", \n",
    "                                     \"Hmmmm, ok then\"]) \n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bae99d-7a63-4a40-bab7-de7d10b8ab1b",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(message, chat_history):\n",
    "        formatted_prompt = format_chat_prompt(message, chat_history)\n",
    "        bot_message = client.generate(formatted_prompt,\n",
    "                                     max_new_tokens=1024,\n",
    "                                     stop_sequences=[\"\\nUser:\", \"<|endoftext|>\"]).generated_text\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79d107f3",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3214f5",
   "metadata": {},
   "source": [
    "#### Implementation using ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6218a973",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client = OpenAI(api_key=os.environ['OPAI_API_KEY'])\n",
    "\n",
    "def chatopenaigenerate(prompt,max_new_tokens):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_new_tokens\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(message, chat_history):\n",
    "        formatted_prompt = format_chat_prompt(message, chat_history)\n",
    "        bot_message = chatopenaigenerate(formatted_prompt,\n",
    "                                     max_new_tokens=100)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "\n",
    "gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b8de8",
   "metadata": {},
   "source": [
    "### Adding other advanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09873dfd-5b6c-41d6-9479-12e8c8894295",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def format_chat_prompt(message, chat_history, instruction):\n",
    "    prompt = f\"System:{instruction}\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(message, chat_history, instruction, temperature=0.7):\n",
    "    prompt = format_chat_prompt(message, chat_history, instruction)\n",
    "    chat_history = chat_history + [[message, \"\"]]\n",
    "    stream = client.generate_stream(prompt,\n",
    "                                      max_new_tokens=1024,\n",
    "                                      stop_sequences=[\"\\nUser:\", \"<|endoftext|>\"],\n",
    "                                      temperature=temperature)\n",
    "                                      #stop_sequences to not generate the user answer\n",
    "    acc_text = \"\"\n",
    "    #Streaming the tokens\n",
    "    for idx, response in enumerate(stream):\n",
    "            text_token = response.token.text\n",
    "\n",
    "            if response.details:\n",
    "                return\n",
    "\n",
    "            if idx == 0 and text_token.startswith(\" \"):\n",
    "                text_token = text_token[1:]\n",
    "\n",
    "            acc_text += text_token\n",
    "            last_turn = list(chat_history.pop(-1))\n",
    "            last_turn[-1] += acc_text\n",
    "            chat_history = chat_history + [last_turn]\n",
    "            yield \"\", chat_history\n",
    "            acc_text = \"\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "        system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "        temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "\n",
    "# In Gradio, both demo.queue().launch() and demo.launch() are used to launch a Gradio interface, but they serve different purposes:\n",
    "\n",
    "# demo.launch(): This is the standard way to launch a Gradio interface. It starts a simple web server that serves the demo.\n",
    "# demo.queue().launch(): This is used when you want to set up a queue for your Gradio interface. The queue helps manage multiple incoming requests, ensuring that they are processed in the order they were received. This can be particularly useful when you’re expecting high traffic or when the function associated with your interface takes a significant amount of time to process.\n",
    "# demo.queue().launch(share=True, server_port=int(os.environ['PORT4']))\n",
    "demo.queue().launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT4']))  # demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b0220",
   "metadata": {},
   "source": [
    "#### Implementation using ChatOpenAI (Steaming and Stop Sequence is not implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "711c34e0",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "import requests\n",
    "from distutils.util import strtobool\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client = OpenAI(api_key=os.environ['OPAI_API_KEY'])\n",
    "\n",
    "def chatopenaigenerate(prompt,instruction,temperature,max_new_tokens=1000):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": instruction\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "#         stream=True\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "    \n",
    "def respond(message, chat_history, instruction, temperature=0.7):\n",
    "    prompt = format_chat_prompt(message, chat_history)\n",
    "    bot_message = chatopenaigenerate(prompt,\n",
    "                                      instruction,\n",
    "                                      temperature=temperature,\n",
    "                                      max_new_tokens=1000)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "        system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "        temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "\n",
    "demo.queue().launch(share=strtobool(os.environ['SHARE']), server_port=int(os.environ['PORT5']))  # demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d9ec80a-39ad-4f58-b79e-4f413c5074c0",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7864\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "465.475px",
    "left": "10px",
    "top": "150px",
    "width": "158.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
